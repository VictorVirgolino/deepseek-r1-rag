RAG em PDFs com Deepseek-r1 e InMemoryVectorStore üìÑü§ñ
Descri√ß√£o

Este projeto implementa um sistema de RAG (Retrieval-Augmented Generation) para consultas inteligentes em documentos PDF. Ele utiliza Deepseek-r1 tanto para a gera√ß√£o de embeddings quanto como modelo de linguagem (LLM), proporcionando uma solu√ß√£o unificada e eficiente para an√°lise de documentos. O armazenamento de embeddings √© feito usando InMemoryVectorStore para r√°pida recupera√ß√£o de informa√ß√µes.

O objetivo √© oferecer uma ferramenta poderosa para buscar e processar informa√ß√µes em PDFs usando intelig√™ncia artificial.
Arquitetura

    Pr√©-processamento de PDFs:
        Os PDFs s√£o extra√≠dos e convertidos em texto.
        Embeddings sem√¢nticos s√£o gerados com o Deepseek-r1 via OllamaEmbeddings.
    Armazenamento:
        Os embeddings s√£o armazenados no InMemoryVectorStore.
    Consultas:
        O usu√°rio faz perguntas relacionadas aos PDFs.
        O sistema recupera os trechos relevantes com base em similaridade sem√¢ntica.
        O Deepseek-r1, como modelo de linguagem, gera respostas contextualizadas.

Tecnologias Utilizadas

    Deepseek-r1: Modelo usado para gera√ß√£o de embeddings e respostas em linguagem natural.
    InMemoryVectorStore: Armazenamento leve e r√°pido de embeddings para desenvolvimento local.
    Python: Linguagem principal para o desenvolvimento.
    LangChain: Para orquestrar o fluxo de trabalho do RAG.
    PDFPlumber: Para extra√ß√£o de texto de PDFs.